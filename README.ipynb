{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13ec761",
   "metadata": {},
   "source": [
    "# Customer churn analysis with low-rank tensor block hazard model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c755f3",
   "metadata": {},
   "source": [
    "The repository is the official implementation of \n",
    "[Causal Customer Churn Analysis with Low-rank Tensor Block Hazard Model](https://arxiv.org/pdf/2405.11377v1), ICML, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381544f",
   "metadata": {},
   "source": [
    "Here we present an example for implementing the proposed framework and compared it with two common models (generalized linear model and Cox proportional hazard). A full list of comparison can be found in `sim.py`. \n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace6933",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c484f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from utils import theta2prob, gen_data_potential_Y_binary, \\\n",
    "    TensorCompletionCovariateBinary, \\\n",
    "    get_theta_binary, get_theta_survival, \\\n",
    "        regime_eval, regime_prec\n",
    "import scipy\n",
    "from sim import main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83752de6",
   "metadata": {},
   "source": [
    "## generate data N = 500, T = 10, k =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb64d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500; T = 10; k = 3; d = 3; seed = 2\n",
    "Y, A, delta, X, theta_true, error = gen_data_potential_Y_binary(seed = seed, N = N, T = T, k = k, d = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c1df4",
   "metadata": {},
   "source": [
    "## estimate the weight propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5be4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_contd_grad(coef, XX_t, A_t):\n",
    "        \n",
    "        N = XX_t.shape[0]\n",
    "        X_cov = np.hstack((np.ones((N, 1)), XX_t))\n",
    "        # compute the weight\n",
    "        linear_pred = np.dot(X_cov, coef)\n",
    "        # obj_grad_CAL = (A_t/expit(linear_pred) -1).dot(XX_t)/N\n",
    "        obj_grad_CAL = (A_t / expit(linear_pred) -1).dot(X_cov)/N\n",
    "        # obj_grad_CAL = (expit(linear_pred) - A_t).dot(XX_t)/N\n",
    "        return obj_grad_CAL\n",
    "def rho_trt(kn):\n",
    "    weights_coef1 = scipy.optimize.root(fun = partial(weight_contd_grad,\n",
    "                                      XX_t = X, A_t = A[:, kn]),\n",
    "                        x0 = np.zeros(d+1),\n",
    "                        # jac = partial(weight_contd_hess,\n",
    "                        #               XX_t = CV_X,\n",
    "                        #               A_t = CV_A),\n",
    "                        method = 'linearmixing').x\n",
    "    weights_coef0 = scipy.optimize.root(fun = partial(weight_contd_grad,\n",
    "                                      XX_t = X, A_t = 1 - A[:, kn]),\n",
    "                        x0 = np.zeros(d+1),\n",
    "                        # jac = partial(weight_contd_hess,\n",
    "                        #               XX_t = CV_X,\n",
    "                        #               A_t = CV_A),\n",
    "                        method = 'linearmixing').x\n",
    "    # compute the estimated propensity weights\n",
    "    rho = expit(X @ weights_coef1[1:] + weights_coef1[0]) * A[:, kn] +\\\n",
    "        expit(X @ weights_coef0[1:] + weights_coef0[0]) * (1-A[:, kn]) \n",
    "    return rho\n",
    "    \n",
    "# focus on past k treatments\n",
    "PS_trt = np.array([rho_trt(kn) for kn in range(k)]) \n",
    "rho = np.apply_along_axis(np.prod, 0, PS_trt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a388d3",
   "metadata": {},
   "source": [
    "## low-rank tensor block hazard model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736dfb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CO-Tucker): 0th iteration with loss: 11.472\n",
      "(CO-Tucker): 1000th iteration with loss: 9.598\n",
      "(CO-Tucker): 2000th iteration with loss: 9.569\n",
      "(CO-Tucker): 3000th iteration with loss: 9.551\n",
      "(CO-Tucker): 4000th iteration with loss: 9.542\n",
      "(CO-Tucker): 5000th iteration with loss: 9.539\n",
      "(CO-Tucker): 6000th iteration with loss: 9.535\n",
      "(CO-Tucker): 7000th iteration with loss: 9.532\n",
      "(CO-Tucker): 8000th iteration with loss: 9.53\n",
      "(CO-Tucker): 9000th iteration with loss: 9.528\n"
     ]
    }
   ],
   "source": [
    "# replace Nan with zero for computational purpose\n",
    "Y[np.isnan(Y)]= 0    \n",
    "# weighted tensor block hazard model\n",
    "TC_bry_w = TensorCompletionCovariateBinary(Y = Y, A = A, X = X, delta = delta,\n",
    "                                           rho = rho,\n",
    "                                           stepsize = 1e-5,     \n",
    "                                           niters = 10000,\n",
    "                                           r1_list = [4], r2_list = [2], r3_list = [k + 1])\n",
    "theta_hat_w = TC_bry_w.SequentialTuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36a7c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized tensor estimation error of GLM: 0.5791\n",
      "\n",
      "Normalized tensor estimation error of CoxPH: 0.6063\n",
      "\n",
      "Normalized tensor estimation error of ours: 0.2505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# obtain the estimated survival curves of generalized linear model\n",
    "est_prob_GLM = theta2prob(get_theta_binary(Y = Y, A = A, X = X, delta = delta,\n",
    "                                          method = 'logit'))\n",
    "# obtain the estimated survival curves of CoxPh model\n",
    "est_prob_CoxPH = get_theta_survival(Y, A, X, delta, method = 'coxPH')\n",
    "# obtain the estimated survival curves of our model\n",
    "est_prob_TC = theta2prob(theta_hat_w)\n",
    "# true survival curves\n",
    "true_prob = theta2prob(theta_true)\n",
    "# output the normalized tensor estimation error\n",
    "print('Normalized tensor estimation error of GLM: {0:.4f}\\n'.format(np.linalg.norm(est_prob_GLM - true_prob)/\\\n",
    "    np.linalg.norm(true_prob)))\n",
    "print('Normalized tensor estimation error of CoxPH: {0:.4f}\\n'.format(np.linalg.norm(est_prob_CoxPH - true_prob)/\\\n",
    "    np.linalg.norm(true_prob)))\n",
    "print('Normalized tensor estimation error of ours: {0:.4f}\\n'.format(np.linalg.norm(est_prob_TC - true_prob)/\\\n",
    "    np.linalg.norm(true_prob)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
